# main.py
from typing import List
from cmc_fetcher import fetch_ucids, fetch_coin_details, fetch_market_data
from data_processor import process_data
from pinecone_manager import init_pinecone_client, get_or_create_index, upsert_data_to_pinecone
from utils import save_ucids_snapshot

def embed_texts_with_pinecone(pc_client, texts: List[str]) -> List[List[float]]:
    """
    ä½¿ç”¨ Pinecone Inference API å¯¹æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–ã€‚
    """
    if not texts:
        return []
    
    print(f"ğŸš€ æ­£åœ¨è°ƒç”¨ Pinecone Inference API å¯¹ {len(texts)} æ¡æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–...")
    try:
        # è°ƒç”¨ API ç”Ÿæˆ embeddingï¼Œå°±åƒæ‚¨æä¾›çš„é‚£æ ·
        response = pc_client.inference.embed(
            model="llama-text-embed-v2",
            inputs=texts,
            parameters={"input_type": "passage", "truncate": "END"}
        )
        
        # ä»å“åº”ä¸­æå–å‘é‡åˆ—è¡¨
        if hasattr(response, 'data') and response.data:
            embeddings = []
            for item in response.data:
                if hasattr(item, 'values'):
                    embeddings.append(item.values)
                else:
                    print(f"âš ï¸ å“åº”é¡¹ç¼ºå°‘ values å±æ€§: {item}")
                    return []
            print(f"âœ… æˆåŠŸè·å– {len(embeddings)} æ¡å‘é‡ã€‚")
            return embeddings
        else:
            print("âŒ å“åº”ä¸­æ²¡æœ‰æ•°æ®")
            return []
        
    except Exception as e:
        print(f"âŒ è°ƒç”¨ Pinecone Inference API å¤±è´¥: {e}")
        return []

def run_sync_process(ucids: List[int]):
    """æ‰§è¡ŒåŒæ­¥çš„æ ¸å¿ƒæµç¨‹"""
    if not ucids:
        print("æ—  UCID éœ€è¦å¤„ç†ã€‚")
        return

    # 1. æ‹‰å–æ•°æ® (ä¸å˜)
    coin_details = fetch_coin_details(ucids)
    market_data = fetch_market_data(ucids)
    if not coin_details or not market_data:
        print("âŒ è·å–è¯¦æƒ…æˆ–å¸‚åœºæ•°æ®å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢")
        return

    # 2. å¤„ç†æ•°æ® (ä¸å˜)
    processed_list = process_data(ucids, coin_details, market_data)
    if not processed_list: return

    # 3. åˆå§‹åŒ– Pinecone å®¢æˆ·ç«¯ (æå‰)
    # å› ä¸ºå‘é‡åŒ–å’Œå­˜å‚¨éƒ½éœ€è¦ç”¨åˆ°å®ƒ
    print("\nåˆå§‹åŒ– Pinecone å®¢æˆ·ç«¯...")
    pc_client = init_pinecone_client()
    if not pc_client: return

    # 4. å‘é‡åŒ– (ä½¿ç”¨æ–°çš„å‡½æ•°)
    texts_to_embed = [item["token_info"] for item in processed_list]
    vectors = embed_texts_with_pinecone(pc_client, texts_to_embed)
    if not vectors: # å¦‚æœå‘é‡åŒ–å¤±è´¥ï¼Œåˆ™ç»ˆæ­¢æµç¨‹
        print("âŒ å‘é‡åŒ–å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
        return

    # 5. å‡†å¤‡æœ€ç»ˆæ•°æ® (ä¸å˜)
    pinecone_data = [
        {"id": item["id"], "values": vectors[i], "metadata": item["metadata"]}
        for i, item in enumerate(processed_list)
    ]
    print("âœ… æ•°æ®å·²è½¬æ¢ä¸º Pinecone æ ¼å¼")

    # 6. å­˜å‚¨åˆ° Pinecone
    print("\nå­˜å‚¨åˆ° Pinecone...")
    index = get_or_create_index(pc_client)
    if not index: return
    upsert_data_to_pinecone(index, pinecone_data)

def main():
    print("=" * 60)
    print("ğŸ“Œ å¼€å§‹æ‰§è¡Œã€é¦–æ¬¡å…¨é‡åŒæ­¥ã€‘æµç¨‹")
    print("=" * 60)

    all_ucids = fetch_ucids()
    if not all_ucids: return
    
    # ä¸ºäº†åœ¨ GitHub Actions ä¸Šé«˜æ•ˆè¿è¡Œï¼Œå¯ä»¥å…ˆå¤„ç†ä¸€ä¸ªå°å­é›†è¿›è¡Œæµ‹è¯•
    # æ­£å¼è¿è¡Œæ—¶è¯·ä½¿ç”¨ all_ucids
    test_ucids = all_ucids[:100] # ä¾‹å¦‚ï¼Œå…ˆæµ‹è¯•100ä¸ª
    print(f"ğŸ” æœ¬æ¬¡å¤„ç† {len(test_ucids)} ä¸ªä»£å¸ (æµ‹è¯•æ¨¡å¼)")
    run_sync_process(test_ucids)

    # print(f"ğŸ” æœ¬æ¬¡å¤„ç† {len(all_ucids)} ä¸ªä»£å¸")
    # run_sync_process(all_ucids)

    print("\nä¿å­˜ UCID å¿«ç…§...")
    save_ucids_snapshot(test_ucids)

    print("\nğŸ‰ å…¨é‡åŒæ­¥æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")

if __name__ == "__main__":
    main()