# main.py
from typing import List
from cmc_fetcher import fetch_ucids, fetch_coin_details, fetch_market_data
from data_processor import process_data
from pinecone_manager import init_pinecone_client, get_or_create_index, upsert_data_to_pinecone
from utils import save_ucids_snapshot
import time

def embed_texts_with_pinecone(pc_client, texts: List[str]) -> List[List[float]]:
    """
    ä½¿ç”¨ Pinecone Inference API å¯¹æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–ã€‚
    æ”¯æŒæ‰¹é‡å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š96æ¡ï¼ˆAPIé™åˆ¶ï¼‰ã€‚
    """
    if not texts:
        return []

    # Pinecone llama-text-embed-v2 æ¨¡å‹çš„è¾“å…¥é™åˆ¶æ˜¯96æ¡
    BATCH_SIZE = 96
    all_embeddings = []

    print(f"ğŸš€ æ­£åœ¨è°ƒç”¨ Pinecone Inference API å¯¹ {len(texts)} æ¡æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–...")

    # åˆ†æ‰¹å¤„ç†
    for i in range(0, len(texts), BATCH_SIZE):
        batch_texts = texts[i:i + BATCH_SIZE]
        batch_num = i // BATCH_SIZE + 1
        total_batches = (len(texts) + BATCH_SIZE - 1) // BATCH_SIZE

        print(f"ğŸ“¦ å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼ŒåŒ…å« {len(batch_texts)} æ¡æ–‡æœ¬...")

        try:
            # è°ƒç”¨ API ç”Ÿæˆ embeddingï¼Œæ·»åŠ é‡è¯•æœºåˆ¶
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    response = pc_client.inference.embed(
                        model="llama-text-embed-v2",
                        inputs=batch_texts,
                        parameters={"input_type": "passage", "truncate": "END"}
                    )
                    break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                except Exception as e:
                    error_str = str(e)
                    is_rate_limit = ("429" in error_str or
                                   "Too Many Requests" in error_str or
                                   "RESOURCE_EXHAUSTED" in error_str or
                                   "max embedding Tokens per minute" in error_str)

                    if is_rate_limit:
                        if attempt < max_retries - 1:
                            wait_time = (attempt + 1) * 60  # é€’å¢ç­‰å¾…ï¼š60s, 120s, 180s
                            print(f"âš ï¸ Pinecone APIé™æµï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})...")
                            time.sleep(wait_time)
                        else:
                            raise  # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    else:
                        raise  # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
        
            # ä»å“åº”ä¸­æå–å‘é‡åˆ—è¡¨
            if hasattr(response, 'data') and response.data:
                batch_embeddings = []
                for item in response.data:
                    if hasattr(item, 'values'):
                        batch_embeddings.append(item.values)
                    else:
                        print(f"âš ï¸ å“åº”é¡¹ç¼ºå°‘ values å±æ€§: {item}")
                        return []
                all_embeddings.extend(batch_embeddings)
                print(f"âœ… ç¬¬ {batch_num} æ‰¹æˆåŠŸè·å– {len(batch_embeddings)} æ¡å‘é‡")
            else:
                print(f"âŒ ç¬¬ {batch_num} æ‰¹å“åº”ä¸­æ²¡æœ‰æ•°æ®")
                return []

        except Exception as e:
            print(f"âŒ ç¬¬ {batch_num} æ‰¹è°ƒç”¨ Pinecone Inference API å¤±è´¥: {e}")
            return []

        # åœ¨æ‰¹æ¬¡ä¹‹é—´æ·»åŠ å»¶è¿Ÿï¼Œé¿å…APIé™æµ
        if batch_num < total_batches:  # ä¸æ˜¯æœ€åä¸€æ‰¹
            print(f"â³ ç­‰å¾… 10 ç§’åå¤„ç†ä¸‹ä¸€æ‰¹...")
            time.sleep(10)

    print(f"ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å®Œæˆï¼æ€»å…±è·å– {len(all_embeddings)} æ¡å‘é‡")
    return all_embeddings

def run_sync_process(ucids: List[int]):
    """æ‰§è¡ŒåŒæ­¥çš„æ ¸å¿ƒæµç¨‹"""
    if not ucids:
        print("æ—  UCID éœ€è¦å¤„ç†ã€‚")
        return

    # 1. æ‹‰å–æ•°æ® (ä¸å˜)
    coin_details = fetch_coin_details(ucids)
    market_data = fetch_market_data(ucids)
    if not coin_details or not market_data:
        print("âŒ è·å–è¯¦æƒ…æˆ–å¸‚åœºæ•°æ®å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢")
        return

    # 2. å¤„ç†æ•°æ® (ä¸å˜)
    processed_list = process_data(ucids, coin_details, market_data)
    if not processed_list: return

    # 3. åˆå§‹åŒ– Pinecone å®¢æˆ·ç«¯ (æå‰)
    # å› ä¸ºå‘é‡åŒ–å’Œå­˜å‚¨éƒ½éœ€è¦ç”¨åˆ°å®ƒ
    print("\nåˆå§‹åŒ– Pinecone å®¢æˆ·ç«¯...")
    pc_client = init_pinecone_client()
    if not pc_client: return

    # 4. å‘é‡åŒ– (ä½¿ç”¨æ–°çš„å‡½æ•°)
    texts_to_embed = [item["token_info"] for item in processed_list]
    vectors = embed_texts_with_pinecone(pc_client, texts_to_embed)
    if not vectors: # å¦‚æœå‘é‡åŒ–å¤±è´¥ï¼Œåˆ™ç»ˆæ­¢æµç¨‹
        print("âŒ å‘é‡åŒ–å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
        return

    # 5. å‡†å¤‡æœ€ç»ˆæ•°æ® (ä¸å˜)
    pinecone_data = [
        {"id": item["id"], "values": vectors[i], "metadata": item["metadata"]}
        for i, item in enumerate(processed_list)
    ]
    print("âœ… æ•°æ®å·²è½¬æ¢ä¸º Pinecone æ ¼å¼")

    # 6. å­˜å‚¨åˆ° Pinecone
    print("\nå­˜å‚¨åˆ° Pinecone...")
    index = get_or_create_index(pc_client)
    if not index: return
    upsert_data_to_pinecone(index, pinecone_data)

def main():
    print("=" * 60)
    print("ğŸ“Œ å¼€å§‹æ‰§è¡Œã€é¦–æ¬¡å…¨é‡åŒæ­¥ã€‘æµç¨‹")
    print("=" * 60)

    all_ucids = fetch_ucids()
    if not all_ucids: return

    print(f"ğŸ” æœ¬æ¬¡å¤„ç† {len(all_ucids)} ä¸ªä»£å¸ (å…¨é‡åŒæ­¥)")
    run_sync_process(all_ucids)

    print("\nä¿å­˜ UCID å¿«ç…§...")
    save_ucids_snapshot(all_ucids)

    print("\nğŸ‰ å…¨é‡åŒæ­¥æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")

if __name__ == "__main__":
    main()